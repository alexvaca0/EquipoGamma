---
title: "Práctica de Modelos Lineales Generalizados"
author: "Gustavo Vargas"
date: "17 de febrero de 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=TRUE ,echo = TRUE, warning = FALSE, message=FALSE)
```


```{r, echo=FALSE}
#### Carga de datos ####
library(data.table)
library(dplyr)
library(ggplot2)
library(GGally)
library(MASS)
library(pscl)
library(caret)
library(effects)
library(grid)
library(gridExtra)

rm(list = ls())

Fair <- fread('Fair.csv')
```

Vamos a analizar una base de datos sobre infidelidades creada en 1970, `Fair`, de 601 filas y 9 variables, que son:

- 1 `sex`             Hombre o mujer. Factor
- 2 `age`             Edad
- 3 `ym`              Años de casado
- 4 `chil`            Número de hijos. Factor.
- 5 `religious`       Si es religiosa. Del 1(antirreligiosa) al 5(muy religiosa)
- 6 `education`       Nivel de educación
- 7 `occupation`      Nivel de educación. Del 1 al 7
- 8 `rate`            Cómo es de feliz, del 1 al 5
- 9 `nbaffairs`       Número de infidelidades

En esta base de datos no hay NAs. Vamos a ver de qué tipo es cada variable, por si necesitamos hacer cambios
```{r,echo=FALSE}
str(Fair)
```


Realizamos los cambios necesarios:

```{r}
Fair$V1 <- NULL

Fair$sex <- factor(Fair$sex)

Fair$child <- factor(Fair$child)

Fair$religious <- factor(Fair$religious, levels=c("1", "2", "3","4","5"), ordered=TRUE)

Fair$occupation <- factor(Fair$occupation, levels=c("1", "2", "3","4","5","6","7"), ordered=TRUE)

Fair$rate <- factor(Fair$rate, levels=c("1", "2", "3","4","5"), ordered=TRUE)
```


## Data partitioning

Partimos el dataset en train y test. Vamos a hacer en análisis con train, y pasaremos a usar el test solo en el apartado final, para predicción.

```{r,eval= TRUE, echo=TRUE, warning=FALSE, message=FALSE}
set.seed(123)
train_ind <- sample(seq_len(nrow(Fair)),size=500)

ftrain <- Fair[train_ind, ]
ftest <- Fair[-train_ind, ]
```




## Análisis univariante

#### Variable `sex`
```{r,echo=FALSE,fig.height=2}
p1 <- qplot(ftrain$sex)
p2 <- ftrain %>%
  group_by(sex) %>% 
  summarise(media_nbaffairs = mean(nbaffairs)) %>% 
  ggplot(aes(x = sex,
             y=media_nbaffairs,
             fill=sex)) +
  geom_histogram(stat='identity')
p3 <- ftrain %>% 
  ggplot(aes(x = rate,fill=sex))+
  geom_bar(position = "dodge")+
  facet_grid(~sex)

grid.arrange(p1, p2, p3, nrow = 1)
```

- Hay menos hombres, pero no muchos menos. Está bien balanceado.
- La infidelidad media, `median_nbaffairs` tampoco parece ser distinta por sexos
- Las mujeres valoran más su matrimonio que los hombres, lo cual puede indicar que luego tengamos más hombres siendo infieles.



####
# ftrain$age ftrain[,2]
####

# En nuestro dataset tenemos mucha más gente alrededor de los 20 y 30 años. El tamaño de la muestra 
# cae drásticamente alrededor de los 35 años
ftrain %>% 
  ggplot(aes(age))+
  geom_histogram(binwidth = 5, col='blue',fill='red',alpha=.2)

# La proporción de gente que no es infiel cae conforme la edad. En cambio, conforme hay más infidelidades
# la proporción de gente aumenta en edades bajas. En cristiano, la gente infiel lo es desde jóven.
ftrain %>%
  group_by(factor(nbaffairs)) %>% 
  ggplot(aes(x = age, fill=factor(nbaffairs))) +
  geom_density(alpha=0.8)+
  facet_wrap(~ factor(nbaffairs))+
  scale_fill_brewer(palette="blue1")



# La proporción de gente que valora mucho su matrimonio es más joven. A medida que valoran menos su
# matrimonio, la distribución es más uniforme.
ftrain %>%
  group_by(factor(rate)) %>% 
  ggplot(aes(x = age, fill=factor(rate))) +
  geom_density(alpha=0.8)+
  facet_wrap(~ factor(rate))+
  scale_fill_brewer(palette="blue1")


####
# ftrain$ym ftrain[,3]
####

qplot(ftrain$ym)
# Gran parte de la muestra llevan casados quince años o más

# La mayor parte de casados no han tenido infidelidades, pero si hacemos proporciones, podemos sacar
# información. Aquí vemos que la distribución de número de engaños según los años de casado cambia 
# el número de engaños. A medida que se cumplen años de casado, aumenta la proporción de infidelidades.
ftrain %>%
  group_by(factor(nbaffairs)) %>% 
  ggplot(aes(x = ym, fill=factor(nbaffairs))) +
  geom_density(alpha=0.8)+
  facet_wrap(~ factor(nbaffairs))+
  scale_fill_brewer()

# Los jóvenes valoran mejor sus matrimonios, y a medida que envejecen, baja esa valoración.
ftrain %>%
  group_by(rate) %>% 
  ggplot(aes(x = ym, fill=rate)) +
  geom_density(alpha=0.8)+
  facet_wrap(~ rate)+
  scale_fill_brewer()


####
# ftrain$child ftrain[,4]
####


qplot(ftrain$child)
summary(ftrain$child)
# Hay mucha más gente con hijos.

# El número de affairs es, de media, el mismo para gente sin hijos que con hijos.
ftrain %>%
  group_by(child) %>% 
  summarise(media_nbaffairs = mean(ftrain$nbaffairs)) %>% 
  ggplot(aes(x = child,
             y=media_nbaffairs,
             fill=child)) +
  geom_histogram(stat='identity')

# Vemos un efecto débil en general, con respecto a que las distribuciones son leptocúrticas (más apuntadas)
# para la gente con hijos, esto es, la gente con hijos suele tener una opinión de su matrimonio menos
# dispersa que los que no los tienen.
ftrain %>%
  group_by(child) %>% 
  ggplot(aes(x = rate, fill=child)) +
  geom_density(alpha=.4)+
  facet_wrap(~ rate,nrow=1)+
  scale_fill_brewer(palette = "Set1")

####
# ftrain$education ftrain[,6]
####

qplot(ftrain$education)

table(ftrain$education)

# Encontramos que las distintas distribuciones de nivel de educación, separadas por el valor que le dan
# a su matrimonio, son básicamente las mismas
ftrain %>%
  group_by(rate) %>% 
  ggplot(aes(x = education, fill=rate)) +
  geom_density(alpha=0.8)+
  facet_wrap(~ rate)+
  scale_fill_brewer()


####
# ftrain$occupation ftrain[,7]
####

qplot(ftrain$occupation)
# Tiene dos máximos relativos

ftrain %>% 
  ggplot(aes(x = occupation, y = nbaffairs))  +
  geom_count(aes(color = ..n.., size = ..n..))+
  guides(color = 'legend')


####
# ftrain$rate ftrain[,8]
####

qplot(ftrain$rate)
# No hay outliers y los valores tienen sentido. Son %

summary(ftrain$rate)

# ftrain %>%
#   ggplot(aes(x = ftrain$rate, y = nbaffairs))+
#   geom_count(aes(color = ..n.., size = ..n..))+
#   guides(color = 'legend')
# 
# ftrain %>%
#   group_by(factor(nbaffairs)) %>% 
#   ggplot(aes(x = rate, fill=factor(nbaffairs))) +
#   geom_density(alpha=.4)+
#   facet_wrap(~ rate+factor(nbaffairs),ncol=5)+
#   scale_fill_brewer(palette = "Set1")


####
# ftrain$nbaffairs ftrain[,9]
####

qplot(ftrain$nbaffairs)

table(ftrain$nbaffairs) 

####
# correlación entre variables
####

ggpairs(ftrain)

ggcorr(ftrain, label = T)
# vemos mucha relación entre la variable age y ym, lo cual tiene sentido, pero no con el target



#### GLM para 'nbaffairs' ####

# Probamos una poisson, sin más, para tener una referencia del AIC
fit.poisson <- glm(nbaffairs ~ .,
                   family = "poisson",
                   data = ftrain)
summary(fit.poisson)
AIC(fit.poisson) #2413.53

# Como la variable nbaffairs es un conteo, la modelaremos al principio como una poisson. Luego probaremos
# si va mejor una quasi poisson y después, una binomial negativa. 

# Como en la gráfica vemos que los ceros son mucho mayores que el resto de números, usaremos los modelos
# anteriores dentro de un modelo de ceros inflados, donde la bernouilli es el modelo para los ceros.

# Ceros inflados seguro
fit.zip1 <- zeroinfl(nbaffairs ~ .,
                     dist = "poisson",
                     data = ftrain)
summary(fit.zip1)
AIC(fit.zip1) #1302.854, mucho menor que el del poisson

# (Aquí tenemos que poner un ejemplo de interpretación de un beta)

# Probamos un ceros inflados con binomial negativa
fit.zip2 <- zeroinfl(nbaffairs ~ .,
                     dist = "negbin",
                     data = ftrain)
summary(fit.zip2)
AIC(fit.zip2) #1213.876, sigue mejorando

# Para comparar modelos, usamos los AIC
AIC.nbaffairs <- c(AIC(fit.poisson), AIC(fit.zip1), AIC(fit.zip2))
AIC.nbaffairs

#### GLM para 'rate' ####

fair.plr <- polr(rate ~ .,
                 data = ftrain)
AIC(fair.plr) #1318.96

summary(fair.plr, digits = 3)

plot(allEffects(fair.plr), rescale.axis=FALSE, multiline=TRUE, rug=FALSE, main="")
# (Comentar la gráfica)



#### Predicción para 'nbaffairs' ####

#Vamos a mirar hallar los errores de las predicciones
pred.na = predict(fit.zip2,    
               newdata=ftest,
               type = "response")

rmse = sqrt(mean((pred.na-ftest$nbaffairs)))
rmse #2.99

# unconditional error. Desviación típica
sd(ftest$nbaffairs)

# R2 in testing set. El R2
cor(pred.na, ftest$nbaffairs)



#### Predicción para 'rate' ####

pred.ra <- predict(fair.plr, ftest, type = "class")

confusionMatrix(reference = ftest$rate, data = pred.ra)