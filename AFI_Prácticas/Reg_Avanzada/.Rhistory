newdata=ftest,
type = "response")
rmse = sqrt(mean((pred.na-ftest$nbaffairs)^2))
rmse
plot(allEffects(fair.plr), rescale.axis=FALSE, multiline=TRUE, rug=FALSE, main="")
pred.ra <- predict(fair.plr, ftest, type = "class")
confusionMatrix(reference = ftest$rate, data = pred.ra)
data <- fread('HomeSalesData.csv')
data <- fread('HomeSalesData.csv')
setwd("C:/Users/gvargas/00 - Máster Data Science AFI/19 - Regresión Avanzada/03 - Práctica")
data <- fread('HomeSalesData.csv')
setwd("~/00/EquipoGamma/AFI_Prácticas/Reg_Avanzada")
library(data.table)
library(tidyverse)
data <- fread('HomeSalesData.csv')
data <- fread('HomeSalesData.csv')
setwd("~/00/EquipoGamma/AFI_Prácticas/Reg_Avanzada")
str(dat)
str(data)
names(data)
data <- fread('HomeSalesData.csv')
dim(data)
sum(is.na(data))
data <- fread('HomeSalesData.csv')
sum(is.na(data))
str(Fair)
str(Data)
str(data)
library(MASS)
library(ISLR)
library(moments)
library(GGally)
library(dplyr)
library(rsq)
library(mlbench)
library(psych)
library(fitdistrplus)
library(lmtest)
library(het.test)
library(sandwich)
library(robustbase)
library(car)
library(nlme)
library(caret)
library(readr)
library(car)
library(ggmap)
library(het.test)
library(lmtest)
library(MASS)
library(ISLR)
library(moments)
install.packages('moments')
library(GGally)
library(dplyr)
library(rsq)
install.packages('rsq')
library(mlbench)
library(ggmap)
library(skimr)
library(mice)
library(tidyverse)
library(caret)
data(Sacramento)
names(Sacramento)
dim(Sacramento)
str(Sacramento)
summary(Sacramento)
# Split data into training and testing sets using the caret package
in_train <- createDataPartition(log(Sacramento$price), p = 0.75, list = FALSE)  # 75% for training
training <- Sacramento[ in_train,]
testing <- Sacramento[-in_train,]
nrow(training)
nrow(testing)
# Restore results
ca_map = readRDS(file = "ca_map.rds")
# Plot the training and test set locations
ggmap(ca_map) +
geom_point(data = testing, aes(x = longitude, y = latitude), col = "red", alpha = .5, size = 3) +
geom_point(data = training, aes(x = longitude, y = latitude), col = "blue", alpha = .2, size = 3)
#devtools::install_github("dkahle/ggmap")
library(ggmap)
devtools::install_github("dkahle/ggmap")
# Restore results
ca_map = readRDS(file = "ca_map.rds")
# Save results
saveRDS(ca_map, file = "ca_map.rds")
ca_map <- get_map(location=c(lon=mean(training$longitude), lat=mean(training$latitude)), zoom=10, maptype='roadmap', color='bw')
#devtools::install_github("dkahle/ggmap")
library(ggmap)
devtools::install_github("dkahle/ggmap")
library(ggmap)
ca_map <- get_map(location=c(lon=mean(training$longitude), lat=mean(training$latitude)), zoom=10, maptype='roadmap', color='bw')
# Price vs Size
ggplot(training, aes(x=sqft, y=log(price))) + ylab("log price") +
geom_point(alpha=0.6) + ggtitle("Price vs size of living area")
# Price vs Size
ggplot(training, aes(x=log(sqft), y=log(price))) +
ylab("log price") +
geom_point(alpha=0.6) +
ggtitle("Price vs size of living area")
# Examine the data
summary(training)
# a bit better:
sum.skim=skim_to_wide(training)
library(skimr)
install.packages('skimr')
library(skimr)
# a bit better:
sum.skim=skim_to_wide(training)
sum.skim[, c(1:6, 9:11, 13, 15:16)]
summary(data)
str(data)
ggplot(training, aes(log(price))) +
geom_density(fill="lightblue") +
xlab("log price") +
ggtitle("Price distribution")
ggplot(training, aes(log(price))) +
geom_density(aes(group=type,
colour=type,
fill=type), alpha=0.1) +
xlab("log price") +
ggtitle("Price distribution")
ggplot(training, aes(x=type,
y=log(price))) +
geom_boxplot(fill="blue") +
ggtitle("Price vs type")
ggplot(training, aes(x=factor(beds),
y=log(price))) +
geom_boxplot(fill="blue") +
ggtitle("Price vs beds")
ggplot(training, aes(x=factor(baths),
y=log(price))) +
geom_boxplot(fill="blue") +
ggtitle("Price vs baths")
# maybe group houses with (baths >= 3.5)?
summary(cut(x = training$baths, breaks = c(0,1,2,3,10)))
ggplot(training, aes(x=city, y=log(price))) +
geom_boxplot(fill="blue") +
ggtitle("Price vs city")
ggplot(training, aes(x=zip, y=log(price))) +
geom_boxplot(fill="blue") +
ggtitle("Price vs zip")
# Which are the most correlated variables with price?
corr_price <- sort(cor(training[,c(3,4,5,7,8,9)])["price",], decreasing = T)
corr=data.frame(corr_price)
# Simple regression: try first the most relevant predictor from previous analysis
linFit <- lm(log(price) ~ sqft, data=training)
summary(linFit)
# Diagnosis
par(mfrow=c(2,2))
plot(linFit, pch=23 ,bg='orange',cex=2)
plot(linFit, pch=23 ,bg='orange',cex=2)
# Try a model selection tool to simplify the model:
library(leaps)
exhaustive <- regsubsets(log(price) ~ beds + baths + log(sqft) + type + latitude*longitude, data=training)
summary(exhaustive)
plot(summary(exhaustive)$bic, type = 'l')
dev.off()
library(mlbench)
library(psych)
library(fitdistrplus)
install.packages('fitdistrsplus')
library(lmtest)
library(het.test)
install.packages('het.test')
library(sandwich)
library(robustbase)
library(car)
library(nlme)
library(caret)
library(readr)
library(car)
library(ggmap)
library(het.test)
library(lmtest)
data <- fread('HomeSalesData.csv')
data <- fread('HomeSalesData.csv')
sum(is.na(data))
names(data)
str(data)
knitr::opts_chunk$set(eval=TRUE ,echo = TRUE, warning = FALSE, message=FALSE)
#### Carga de datos ####
library(data.table)
library(tidyverse)
library(MASS)
library(ISLR)
library(moments)
library(GGally)
library(dplyr)
library(rsq)
library(mlbench)
library(psych)
library(fitdistrplus)
library(psych)
library(lmtest)
library(het.test)
install.packages('fitdistrplus')
library(fitdistrplus)
library(lmtest)
install.packages('het.test')
library(het.test)
library(sandwich)
library(robustbase)
library(car)
library(nlme)
library(caret)
library(readr)
library(car)
library(ggmap)
library(het.test)
library(lmtest)
#### Carga de datos ####
library(data.table)
library(tidyverse)
library(MASS)
library(ISLR)
library(moments)
library(GGally)
library(dplyr)
library(rsq)
library(mlbench)
library(psych)
library(fitdistrplus)
library(lmtest)
library(het.test)
library(sandwich)
library(robustbase)
library(car)
library(nlme)
library(caret)
library(readr)
library(car)
library(ggmap)
library(het.test)
library(lmtest)
data <- fread('HomeSalesData.csv')
str(data)
data$waterfront <- as.factor(data$waterfront)
data$view <- as.factor(data$view)
data$condition <- as.factor(data$condition)
data$zipcode <- as.factor(data$zipcode)
data$sqft_basement <- factor(ifelse(data$sqft_basement>0,1,0))
data <- data[,-c(1,2)]
data$yr_renovated <- as.factor(ifelse(is.na(data$yr_renovated), NA,
ifelse(data$yr_renovated== 0, 0,
ifelse(data$yr_renovated < 1995, 1, 2))))
data$yr_built <- as.factor(ifelse(is.na(data$yr_built), NA,
ifelse(data$yr_built <= 1985, 0,
ifelse(data$yr_built > 1985 & data$yr_built < 2010, 1, 2))))
ModelP <- log1p(price)~sqft_living + floors + waterfront + view +
condition + grade
linFit <- lm(ModelP, data=HouseingTrain)
spl <- createDataPartition(log(data$price), p = 0.80, list = FALSE)
HousingTrain <- data[ spl,]
HousingTest<- data[-spl,]
dim(HousingTrain)
dim(HousingTest)
linFit <- lm(ModelP, data=HouseingTrain)
linFit <- lm(ModelP, data=HousingTrain)
summary(linFit)
linFit$coefficients[ , 2]
linFit$coefficients[2, 2]
linFit$Coefficients[2, 2]
linFit$Coefficients
linFit$coefficients
linFit$residuals
linFit$df.residual
linFit$qr
linFit$effects
linFit$terms
linFit$call
linFit <- lm(log1p(price)~ sqft_living + floors + waterfront + view + condition + grade, data=HousingTrain)
summary(linFit)
linFit <- lm(log1p(price) ~ bathrooms + sqft_living + floors + waterfront + view + condition + grade, data=HousingTrain)
summary(linFit)
#### Carga de datos ####
library(data.table)
library(tidyverse)
library(leaps)
library(MASS)
library(ISLR)
library(moments)
library(GGally)
library(dplyr)
library(rsq)
library(mlbench)
library(psych)
library(fitdistrplus)
library(lmtest)
library(het.test)
library(sandwich)
library(robustbase)
library(car)
library(nlme)
library(caret)
library(readr)
library(car)
library(ggmap)
library(het.test)
library(lmtest)
exhaustive <- regsubsets(log1p(price) ~ bathrooms + sqft_living + floors + waterfront + view + condition + grade, data=HousingTrain)
summary(exhaustive)
plot(summary(exhaustive)$bic, type = 'l')
linFit2 <- lm(log1p(price) ~ bedrooms + bathrooms + sqft_living + floors + waterfront + view + condition + grade + sqft_living15 + , data=HousingTrain)
linFit2 <- lm(log1p(price) ~ bedrooms + bathrooms + sqft_living + floors + waterfront + view + condition + grade + sqft_living15, data=HousingTrain)
summary(linFit2)
ctrl <- trainControl(method = "repeatedcv",
repeats = 2,
number = 5)
test_results <- data.frame(precio = log(HousingTest$price))
ModelP = log1p(price) ~ bedrooms + bathrooms + sqft_living + floors + waterfront + view + condition + grade + sqft_living15
test_results <- data.frame(price = log(HousingTest$price))
lm_tune <- train(ModelS, data = HousingTrain,
method = "lm",
preProc=c('scale', 'center'),
trControl = ctrl)
lm_tune <- train(ModelP, data = HousingTrain,
method = "lm",
preProc=c('scale', 'center'),
trControl = ctrl)
lm_tune
test_results$lm <- predict(lm_tune, HousingTrain)
lm_tune <- train(ModelP, data = HousingTrain,
method = "lm",
preProc=c('scale', 'center'),
trControl = ctrl)
lm_tune
test_results$lm <- predict(lm_tune, HousingTest)
postResample(pred = test_results$lm,  obs = test_results$price)
qplot(test_results$lm, test_results$price) +
labs(title="Linear Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
qplot(test_results$lm, test_results$price) +
labs(title="Regresión lineal Observada vs Predicha", x="Predicción", y="Observación") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue")
qplot(test_results$lm, test_results$price) +
labs(title="Regresión lineal Observada vs Predicha", x="Predicción", y="Observación")+
geom_abline(intercept = 0, slope = 1, colour = "blue")
qplot(test_results$lm, test_results$price) +
labs(title="Regresión lineal Observada vs Predicha", x="Predicción", y="Observación")+
geom_abline(intercept = 0, slope = 1, colour = "blue")
qplot(test_results$lm, test_results$price) +
labs(title="Regresión lineal", x="Predicción", y="Observación")+
geom_abline(intercept = 0, slope = 1, colour = "blue")
qplot(test_results$lm, test_results$price) +
labs(title="Regresión lineal", x="Predicción", y="Observación")+
geom_abline(intercept = 0, slope = 1, colour = "blue")
for_tune <- train(ModelP, data = HousingTrain,
method = "leapForward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
for_tune
plot(for_tune)
for_tune <- train(ModelP, data = HousingTrain,
method = "leapForward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:15),
trControl = ctrl)
for_tune
plot(for_tune)
coef(for_tune$finalModel, for_tune$bestTune$nvmax)
test_results$frw <- predict(for_tune, testing)
coef(for_tune$finalModel, for_tune$bestTune$nvmax)
test_results$frw <- predict(for_tune, HousingTest)
postResample(pred = test_results$frw,  obs = test_results$price)
qplot(test_results$frw, test_results$price) +
labs(title="Forward Regression Observed VS Predicted", x="Predicted", y="Observed") +
lims(x = c(10, 15), y = c(10, 15)) +
geom_abline(intercept = 0, slope = 1, colour = "blue") +
theme_bw()
# some bias, very similar to lm
qplot(test_results$frw, test_results$price) +
labs(title="Forward Regression", x="Predicted", y="Observed")
geom_abline(intercept = 0, slope = 1, colour = "blue")
qplot(test_results$frw, test_results$price) +
labs(title="Forward Regression", x="Predicted", y="Observed")
geom_abline(intercept = 0, slope = 1, colour = "blue")
qplot(test_results$frw, test_results$price) +
labs(title="Forward Regression", x="Predicted", y="Observed")
geom_abline(intercept = 0, slope = 1, colour = "blue")
back_tune <- train(ModelF, data = HousingTrain,
method = "leapBackward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
back_tune <- train(ModelP, data = HousingTrain,
method = "leapBackward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
coef(back_tune$finalModel, back_tune$bestTune$nvmax)
test_results$bw <- predict(back_tune, testing)
coef(back_tune$finalModel, back_tune$bestTune$nvmax)
test_results$bw <- predict(back_tune, HousingTest)
postResample(pred = test_results$bw,  obs = test_results$price)
coef(back_tune$finalModel, back_tune$bestTune$nvmax)
test_results$bw <- predict(back_tune, HousingTest)
postResample(pred = test_results$bw,  obs = test_results$price)
qplot(test_results$bw, test_results$price) +
labs(title="Backward Regression", x="Predecido", y="Observado")
geom_abline(intercept = 0, slope = 1, colour = "blue")
qplot(test_results$bw, test_results$price) +
labs(title="Backward Regression", x="Predecido", y="Observado")+
geom_abline(intercept = 0, slope = 1, colour = "blue")
step_tune <- train(ModelP, data = HousingTrain,
method = "leapSeq",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
plot(step_tune)
step_tune <- train(ModelP, data = HousingTrain,
method = "leapSeq",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:10),
trControl = ctrl)
plot(step_tune)
coef(step_tune$finalModel, step_tune$bestTune$nvmax)
test_results$seq <- predict(step_tune, HousingTest)
postResample(pred = test_results$seq,  obs = test_results$price)
knitr::opts_chunk$set(eval=FALSE ,echo = TRUE, warning = FALSE, message=FALSE)
qplot(test_results$frw, test_results$price) +
labs(title="Forward Regression", x="Predicted", y="Observed")+
geom_abline(intercept = 0, slope = 1, colour = "blue")
back_tune <- train(ModelP, data = HousingTrain,
method = "leapBackward",
preProc=c('scale', 'center'),
tuneGrid = expand.grid(nvmax = 4:15),
trControl = ctrl)
coef(back_tune$finalModel, back_tune$bestTune$nvmax)
test_results$bw <- predict(back_tune, HousingTest)
postResample(pred = test_results$bw,  obs = test_results$price)
ridge_grid <- expand.grid(lambda = seq(0, .1, length = 20))
ridge_tune <- train(ModelF, data = HousingTrain,
method='ridge',
preProc=c('scale','center'),
tuneGrid = ridge_grid,
trControl=ctrl)
ridge_grid <- expand.grid(lambda = seq(0, .1, length = 20))
ridge_tune <- train(ModelP, data = HousingTrain,
method='ridge',
preProc=c('scale','center'),
tuneGrid = ridge_grid,
trControl=ctrl)
plot(ridge_tune)
ridge_tune$bestTune
test_results$ridge <- predict(ridge_tune, HousingTest)
postResample(pred = test_results$ridge,  obs = test_results$price)
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 20))
lasso_tune <- train(ModelF, data = HousingTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 20))
lasso_tune <- train(ModelP, data = HousingTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
plot(lasso_tune)
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 20))
lasso_tune <- train(ModelP, data = HousingTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
plot(lasso_tune)
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 20))
lasso_tune <- train(ModelP, data = HousingTrain,
method='lasso',
preProc=c('scale','center'),
tuneGrid = lasso_grid,
trControl=ctrl)
plot(lasso_tune)
lasso_tune$bestTune
test_results$lasso <- predict(lasso_tune, HousingTest)
postResample(pred = test_results$lasso,  obs = test_results$price)
lasso_tune$bestTune
test_results$lasso <- predict(lasso_tune, HousingTest)
postResample(pred = test_results$lasso,  obs = test_results$price)
lasso_tune$bestTune
test_results$lasso <- predict(lasso_tune, HousingTest)
postResample(pred = test_results$lasso,  obs = test_results$price)
elastic_grid = expand.grid(alpha = seq(0, .2, 0.01), lambda = seq(0, .1, 0.01))
glmnet_tune <- train(ModelF, data = HousingTrain,
method='glmnet',
preProc=c('scale','center'),
tuneGrid = elastic_grid,
trControl=ctrl)
modelLookup('glmnet')
elastic_grid = expand.grid(alpha = seq(0, .2, 0.01), lambda = seq(0, .1, 0.01))
glmnet_tune <- train(ModelF, data = HousingTrain,
method='glmnet',
preProc=c('scale','center'),
tuneGrid = elastic_grid,
trControl=ctrl)
modelLookup('glmnet')
elastic_grid = expand.grid(alpha = seq(0, .2, 0.01), lambda = seq(0, .1, 0.01))
glmnet_tune <- train(ModelP, data = HousingTrain,
method='glmnet',
preProc=c('scale','center'),
tuneGrid = elastic_grid,
trControl=ctrl)
plot(glmnet_tune)
glmnet_tune$bestTune
test_results$glmnet <- predict(glmnet_tune, HousingTest)
postResample(pred = test_results$glmnet,  obs = test_results$price)
